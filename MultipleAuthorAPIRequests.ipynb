{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config import api_key\n",
    "from pandas.io.json import json_normalize  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Scopus Author Information using Multiple Scopus Author IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File to Load\n",
    "radiation_oncology = \"radiation_oncology.csv\"\n",
    "\n",
    "# Read the CSV file and store into Pandas DataFrame with the column Scopus Author ID as a string\n",
    "radiation_oncology_df = pd.read_csv(radiation_oncology, encoding=\"utf-8\")\n",
    "\n",
    "#Change the column names to lower case with underscore for spaces\n",
    "radiation_oncology_df.columns =  radiation_oncology_df.columns.str.strip().str.lower().str.replace(\" \", \"_\").str.replace(\"(\",\"\").str.replace(\")\",\"\")\n",
    "radiation_oncology_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the column names in the dataframe\n",
    "radiation_oncology_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the data type in the dataframe columns called scopus_author_id and scopus_search\n",
    "# radiation_oncology_df.scopus_author_id.dtype\n",
    "# radiation_oncology_df.scopus_search.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the column called scopus_author_id to a list called Author_ID_List\n",
    "author_ID_List = radiation_oncology_df['scopus_author_id'].tolist()\n",
    "print(author_ID_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the Author_ID_List to remove nan\n",
    "cleaned_Author_ID_List = [x for x in author_ID_List if str(x) != 'nan']\n",
    "print(cleaned_Author_ID_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the necessary syntax to the cleaned_Author_ID_List\n",
    "scopus_Mulitple_AuthorID_Query = []\n",
    "for x in cleaned_Author_ID_List:\n",
    "    authorID_string = \"\".join((\"AU-ID(\", x,\")\"))\n",
    "    scopus_Mulitple_AuthorID_Query.append(authorID_string)\n",
    "    \n",
    "print(scopus_Mulitple_AuthorID_Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scopus_Search_List = radiation_oncology_df['scopus_search'].tolist()\n",
    "# print(scopus_Search_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_Scopus_Search_List = [x for x in scopus_Search_List if str(x) != 'nan']\n",
    "# print(cleaned_Scopus_Search_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://dev.elsevier.com/guides/ScopusSearchViews.htm\n",
    "#https://stackoverflow.com/questions/53558837/python-loop-to-pull-api-data-for-iterating-urls\n",
    "#https://stackoverflow.com/questions/36410800/python-3-parse-json-from-multiple-api-requests-into-a-list-and-output-to-a-fil\n",
    "#https://www.pluralsight.com/guides/web-scraping-with-request-python\n",
    "\n",
    "multiple_author_list = []\n",
    "multiple_author_dict = {}\n",
    "# outfilepath = \"multiple_author_json.json\"\n",
    "# keys = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"]\n",
    "\n",
    "def get_scopus_articles(scopus_Mulitple_AuthorID_Query):\n",
    "    \n",
    "    for authorid in scopus_Mulitple_AuthorID_Query:\n",
    "        url = \"http://api.elsevier.com/content/search/scopus?\"\n",
    "        fieldList = [\"dc:identifier\", \"eid\", \"dc:title\",\"prism:aggregationType\", \"subtype\", \"citedby-count\",\n",
    "                     \"prism:publicationName\",\"prism:volume\",\"prism:issueIdentifier\", \"prism:pageRange\", \n",
    "                     \"prism:coverDate\", \"prism:doi\",\"pubmed-id\", \"authid\", \"authname\"]\n",
    "                    \n",
    "        headers = {\n",
    "             \"X-ELS-APIKey\": api_key,\n",
    "             'Accept':'application/json'\n",
    "        }\n",
    "        parameters = {\n",
    "            \"query\": authorid,\n",
    "            \"field\": \",\".join(fieldList),\n",
    "            \"date\": \"2002-2003\"\n",
    "        }\n",
    "        \n",
    "        #Make the API request \n",
    "        single_author_response = requests.get(url, headers=headers, params=parameters)\n",
    "        #print(single_author_response.url)\n",
    "        #print(single_author_response.status_code)\n",
    "        \n",
    "              \n",
    "        #Append each single_author_dict response to multiple_author_list to create a list of dictionaries\n",
    "        single_author_dict = single_author_response.json()\n",
    "        #print(type(single_author_dict)) \n",
    "        #print(single_author_dict)\n",
    "        multiple_author_list.append(single_author_dict.copy())\n",
    "    \n",
    "    return multiple_author_list\n",
    "       \n",
    "get_scopus_articles(scopus_Mulitple_AuthorID_Query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/48177934/flatten-or-unpack-list-of-nested-dicts-in-dataframe\n",
    "#https://stackoverflow.com/questions/50161070/convert-list-of-dicts-of-dict-into-dataframe\n",
    "#https://stackoverflow.com/questions/43984865/python-having-trouble-returning-a-pandas-data-frame-from-a-user-defined-functio\n",
    "#https://stackoverflow.com/questions/37668291/flatten-double-nested-json\n",
    "\n",
    "def make_scopus_articles_df(multiple_author_list):\n",
    "        #final_list = json_normalize(multiple_author_list, meta=[\"search-results\"], record_path=[\"search-results\", \"entry\"])\n",
    "    scopus_articles_df = pd.DataFrame.from_dict(json_normalize(multiple_author_list, meta=[\"search-results\"], record_path=[\"search-results\", \"entry\"]),orient=\"columns\")\n",
    "    \n",
    "    return scopus_articles_df\n",
    "\n",
    "scopus_articles_df = make_scopus_articles_df(multiple_author_list)\n",
    "make_scopus_articles_df(multiple_author_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/29325458/dictionary-column-in-pandas-dataframe/29330853\n",
    "def fix_dataframe(scopus_articles_df):\n",
    "    remove_searchresults_nest = pd.concat([scopus_articles_df.drop(['search-results'], axis=1), scopus_articles_df['search-results'].apply(pd.Series)], axis=1)\n",
    "    remove_opensearchQuery_nest = pd.concat([remove_searchresults_nest.drop(['opensearch:Query'], axis=1), remove_searchresults_nest['opensearch:Query'].apply(pd.Series)], axis=1)\n",
    "    remove_opensearchQuery_nest = pd.concat([remove_searchresults_nest.drop(['opensearch:Query'], axis=1), remove_searchresults_nest['opensearch:Query'].apply(pd.Series)], axis=1)\n",
    "    return remove_opensearchQuery_nest\n",
    "\n",
    "remove_opensearchQuery_nest = fix_dataframe(scopus_articles_df)\n",
    "fix_dataframe(scopus_articles_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove_opensearchQuery_nest.to_csv (r'C:\\Users\\keg827\\Documents\\10. WorkStuff_KEG\\scopusAPIrequests\\export_dataframe.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/48637219/iterate-over-a-dictionary-of-list-of-dictionaries-in-pandas-dataframe\n",
    "authorids = []\n",
    "authornames = []\n",
    "\n",
    "\n",
    "for item in remove_opensearchQuery_nest[\"author\"][1]:\n",
    "    #print(item.keys())\n",
    "    #print(item.values())\n",
    "    #print(item[\"authid\"])\n",
    "    authorids.append(item[\"authid\"])\n",
    "    authornames.append(item[\"authname\"])\n",
    "print(authornames)\n",
    "print(authorids)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df = remove_opensearchQuery_nest.fillna(\"0\")\n",
    "new_df = remove_opensearchQuery_nest\n",
    "\n",
    "# new_df.loc[new_df['author'].isnull(), 'author'] = {}\n",
    "for row in new_df.loc[new_df.author.isnull(), 'author'].index:\n",
    "    new_df.at[row, 'author'] = []\n",
    "    \n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.reindex(columns=[*new_df.columns.tolist(), 'author_id', 'author_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in new_df.loc[new_df.author_id.isnull(), 'author_id'].index:\n",
    "    new_df.at[row, 'author_id'] = []\n",
    "    \n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['56018970700']\n",
      "['56018970700', '6701662630']\n",
      "['56018970700', '6701662630', '7404024068']\n",
      "['56018970700', '6701662630', '7404024068', '6701854664']\n",
      "['56018970700', '6701662630', '7404024068', '6701854664', '7102541014']\n",
      "['56018970700', '6701662630', '7404024068', '6701854664', '7102541014', '7005140598']\n",
      "['56018970700', '6701662630', '7404024068', '6701854664', '7102541014', '7005140598', '7102955789']\n",
      "['56018970700', '6701662630', '7404024068', '6701854664', '7102541014', '7005140598', '7102955789', '6701449622']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-460-08d7e74659ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mauthornames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mget_author_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-460-08d7e74659ec>\u001b[0m in \u001b[0;36mget_author_ids\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauthorids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[1;31m#authornames.append(item[\"authname\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mnew_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"author_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mauthorids\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mauthorids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mauthornames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3368\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3369\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3370\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3372\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3444\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3445\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3446\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3629\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3630\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3631\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3632\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index, copy)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Length of values does not match length of index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "authorids = []\n",
    "authornames = []\n",
    "#string = new_df[\"author\"]\n",
    "\n",
    "\n",
    "def get_author_ids():\n",
    "    authorids = []\n",
    "    authornames = []\n",
    "    for column in new_df['author']:\n",
    "        #print(column)\n",
    "        if column == []:\n",
    "            continue\n",
    "        else:\n",
    "            for item in column:\n",
    "                #print(item)\n",
    "        #       print(item[\"authid\"])\n",
    "        #       print(column)\n",
    "                authorids.append(item[\"authid\"])\n",
    "                print(authorids)\n",
    "                #authornames.append(item[\"authname\"])\n",
    "            new_df[\"author_id\"]= authorids \n",
    "        authorids=[]\n",
    "        authornames = []\n",
    "    \n",
    "get_author_ids()\n",
    "\n",
    "new_df.head()\n",
    "\n",
    "#remove_opensearchQuery_nest.apply(lambda x: func(x['author']),axis=1)\n",
    "# if column == \"none\":\n",
    "#             continue\n",
    "#         else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'authid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-459-ab066f542e84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Enumerate ages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'authid'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmyList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauthid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'authid' is not defined"
     ]
    }
   ],
   "source": [
    "authorids = []\n",
    "authornames = []\n",
    "#test = new_df[\"author\"]\n",
    "# for item in test.iteritems():\n",
    "#     print(item.key)\n",
    "# #     #print(item.values())\n",
    "# #     #print(item[\"authid\"])\n",
    "#     authorids.append(item[\"authid\"])\n",
    "#     authornames.append(item[\"authname\"])\n",
    "# print(authornames)\n",
    "# print(authorids)  \n",
    "\n",
    "\n",
    "myList = new_df[\"author\"][1]\n",
    "\n",
    "# Enumerate ages\n",
    "for i, age in enumerate(d['authid'] for d in myList): \n",
    "    print(authid)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# new_df['authorID_list'] = new_df['author'].apply(lambda x: x[\"authid\"])\n",
    "# new_df\n",
    "\n",
    "new_df['authorIDs'] = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
